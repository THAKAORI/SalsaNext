{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import datetime\n",
    "import os\n",
    "import shutil\n",
    "from shutil import copyfile\n",
    "import __init__ as booger\n",
    "import yaml\n",
    "from tasks.semantic.modules.data_analysis import *\n",
    "from pip._vendor.distlib.compat import raw_input\n",
    "\n",
    "from tasks.semantic.modules.SalsaNextAdf import *\n",
    "from tasks.semantic.modules.SalsaNext import *\n",
    "#from tasks.semantic.modules.save_dataset_projected import *\n",
    "import math\n",
    "from decimal import Decimal\n",
    "import numpy as np\n",
    "\n",
    "import open3d as o3d\n",
    "from open3d import JVisualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset /workspace/datadir/dataset\n",
      "Opening arch config file /workspace/dllearn/SalsaNext/salsanext.yml\n",
      "Opening data config file /workspace/dllearn/SalsaNext/train/tasks/semantic/config/labels/semantic-kitti.yaml\n",
      "Sequences folder exists! Using sequences from /workspace/datadir/dataset/sequences\n",
      "parsing seq 00\n",
      "parsing seq 01\n",
      "parsing seq 02\n",
      "parsing seq 03\n",
      "parsing seq 04\n",
      "parsing seq 05\n",
      "parsing seq 06\n",
      "parsing seq 07\n",
      "parsing seq 09\n",
      "parsing seq 10\n",
      "Using 19130 scans from sequences [0, 1, 2, 3, 4, 5, 6, 7, 9, 10]\n",
      "Using 19130 poses\n",
      "Sequences folder exists! Using sequences from /workspace/datadir/dataset/sequences\n",
      "parsing seq 08\n",
      "Using 4071 scans from sequences [8]\n",
      "Using 4071 poses\n"
     ]
    }
   ],
   "source": [
    "dataset = \"/workspace/datadir/dataset\"\n",
    "log = \"/workspace/datadir/visualization\"\n",
    "\n",
    "print(\"dataset\", dataset)\n",
    "# open arch config file\n",
    "try:\n",
    "    arch_file = \"/workspace/dllearn/SalsaNext/salsanext.yml\"\n",
    "    print(\"Opening arch config file %s\" % arch_file)\n",
    "    ARCH = yaml.safe_load(open(arch_file, 'r'))\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(\"Error opening arch yaml file.\")\n",
    "    quit()\n",
    "\n",
    "# open data config file\n",
    "try:\n",
    "    data_cfg = \"/workspace/dllearn/SalsaNext/train/tasks/semantic/config/labels/semantic-kitti.yaml\"\n",
    "    print(\"Opening data config file %s\" % data_cfg)\n",
    "    DATA = yaml.safe_load(open(data_cfg, 'r'))\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(\"Error opening data yaml file.\")\n",
    "    quit()\n",
    "\n",
    "# create trainer and start the training\n",
    "dataanalysis = DataAnalysis(ARCH, DATA, dataset, log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pcd = dataanalysis.datao3d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#o3d.io.write_point_cloud(log + \"/input.ply\", pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "open_scan() missing 3 required positional arguments: 'prefile', 'prepose', and 'curpose'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-af500a05c99e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpoints0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpose0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscan_file0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msem_label0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataanalysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpointspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpoints1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpose1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscan_file1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msem_label1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataanalysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpointspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/dllearn/SalsaNext/train/tasks/semantic/modules/data_analysis.py\u001b[0m in \u001b[0;36mgetpointspose\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mtrain_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0mproj_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproj_segment_angle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproj_xyz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproj_remission\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproj_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproj_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscan_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msem_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscan_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msem_label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/dllearn/SalsaNext/train/tasks/semantic/dataset/kitti/data_extractor.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;31m# open and obtain scan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m     \u001b[0mscan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_scan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscan_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m       \u001b[0mscan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: open_scan() missing 3 required positional arguments: 'prefile', 'prepose', and 'curpose'"
     ]
    }
   ],
   "source": [
    "points0, pose0, scan_file0, sem_label0 = dataanalysis.getpointspose(0)\n",
    "points1, pose1, scan_file1, sem_label1 = dataanalysis.getpointspose(70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scan_file0)\n",
    "print(scan_file1)\n",
    "print(pose0.reshape(3,4))\n",
    "print(pose1.reshape(3,4))\n",
    "print(points0.shape)\n",
    "print(points1.shape)\n",
    "print(sem_label0.shape)\n",
    "print(sem_label1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def changecor(point):\n",
    "#     temp = np.zeros(4, dtype=np.float)\n",
    "#     temp[0] = -point[1]\n",
    "#     temp[1] = -point[2]\n",
    "#     temp[2] = point[0]\n",
    "#     temp[3] = 1\n",
    "#     return temp\n",
    "\n",
    "# def TranformWorld(points, pose):\n",
    "#     x = pose[0:4]\n",
    "#     y = pose[4:8]\n",
    "#     z = pose[8:12]\n",
    "#     trans = np.vstack((x, y, z))\n",
    "#     print(trans)\n",
    "#     world_points = np.array([np.dot(trans, changecor(point)) for point in points])\n",
    "#     return world_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TranformWorld(points, pose):\n",
    "    x = pose[0:4]\n",
    "    y = pose[4:8]\n",
    "    z = pose[8:12]\n",
    "    temp = np.vstack((x, y, z))\n",
    "    trans = np.zeros_like(temp)\n",
    "    trans[:, 0] = temp[:, 2]\n",
    "    trans[:, 1] = -temp[:, 0]\n",
    "    trans[:, 2] = -temp[:, 1]\n",
    "    trans[:, 3] = temp[:, 3]\n",
    "    world_points = np.array([np.dot(trans, np.append(point, 1)) for point in points])\n",
    "    return world_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# world_points0 = TranformWorld(points0, pose0)\n",
    "# world_points1 = TranformWorld(points1, pose1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colorize = np.array([[0,0,0], [245, 150, 100], [245, 230, 100], [150, 60, 30], [180, 30, 80], [255, 0, 0], [30, 30, 255], [200, 40, 255], [90, 30, 150], [255, 0, 255], [255, 150, 255], [75, 0, 75], [75, 0, 175], [0, 200, 255], [50, 120, 255], [0, 175, 0], [0, 60, 135], [80, 240, 150], [150, 240, 255], [0, 0, 255]], dtype=np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N0, _ = points0.shape\n",
    "N1, _ = points1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors0 = np.array([colorize[label] / 255. for label in sem_label0])\n",
    "colors1 = np.array([colorize[label] / 255. for label in sem_label1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# points = np.vstack((world_points0, world_points1))\n",
    "# colors = np.vstack((colors0, colors1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pcd = o3d.geometry.PointCloud()\n",
    "# pcd.points = o3d.utility.Vector3dVector(points)\n",
    "# pcd.colors = o3d.utility.Vector3dVector(colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#o3d.io.write_point_cloud(log + \"/world.ply\", pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def changeTrCor(temp):\n",
    "#     trans = np.zeros_like(temp)\n",
    "#     trans[:, 0] = temp[:, 2]\n",
    "#     trans[:, 1] = -temp[:, 0]\n",
    "#     trans[:, 2] = -temp[:, 1]\n",
    "#     trans[:, 3] = temp[:, 3]\n",
    "    \n",
    "#     return trans\n",
    "\n",
    "def TransformC2C(points, pose_f, pose_t):\n",
    "    trans_f = pose_f.reshape(3, 4)\n",
    "    trans_t = pose_t.reshape(3, 4)\n",
    "    trans_f = trans_f[:, [2, 0, 1, 3]]\n",
    "    trans_f[:, 1] *= -1\n",
    "    trans_f[:, 2] *= -1\n",
    "    trans_t = trans_t[:, [2, 0, 1, 3]]\n",
    "    trans_t[:, 1] *= -1\n",
    "    trans_t[:, 2] *= -1\n",
    "    \n",
    "    world_points = np.array([np.dot(trans_f, np.append(point, 1)) for point in points])\n",
    "    \n",
    "    shift = -trans_t[:, 3]\n",
    "    rot = np.linalg.inv(trans_t[:, 0:3])\n",
    "    anocamera_points = np.array([np.dot(rot, point+shift) for point in world_points])\n",
    "    return anocamera_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transpoints0 = TransformC2C(points0, pose0, pose1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = np.vstack((transpoints0, points1))\n",
    "colors = np.vstack((colors0, colors1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(points)\n",
    "pcd.colors = o3d.utility.Vector3dVector(colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.io.write_point_cloud(log + \"/trans.ply\", pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(sem_label1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[0,1,2],[3,1,0],[2,1,3]])\n",
    "print(a)\n",
    "a_on = np.array([np.identity(4)[a_row] for a_row in a])\n",
    "print(a_on)\n",
    "print(a_on.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_on[1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
